{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e8f5627",
   "metadata": {},
   "source": [
    "## Module 1 Homework (2025 cohort)\n",
    "\n",
    "In this homework, we're going to download finance data from various sources and make simple calculations or analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52768cc2",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 1: [Index] S&P 500 Stocks Added to the Index\n",
    "\n",
    "**Which year had the highest number of additions?**\n",
    "\n",
    "Using the list of S&P 500 companies from Wikipedia's [S&P 500 companies page](https://en.wikipedia.org/wiki/List_of_S%26P_500_companies), download the data including the year each company was added to the index.\n",
    "\n",
    "Hint: you can use [pandas.read_html](https://pandas.pydata.org/docs/reference/api/pandas.read_html.html) to scrape the data into a DataFrame.\n",
    "\n",
    "Steps:\n",
    "1. Create a DataFrame with company tickers, names, and the year they were added.\n",
    "2. Extract the year from the addition date and calculate the number of stocks added each year.\n",
    "3. Which year had the highest number of additions (1957 doesn't count, as it was the year when the S&P 500 index was founded)? Write down this year as your answer (the most recent one, if you have several records).\n",
    "\n",
    "*Context*: \n",
    "> \"Following the announcement, all four new entrants saw their stock prices rise in extended trading on Friday\" - recent examples of S&P 500 additions include DASH, WSM, EXE, TKO in 2025 ([Nasdaq article](https://www.nasdaq.com/articles/sp-500-reshuffle-dash-tko-expe-wsm-join-worth-buying)).\n",
    "\n",
    "*Additional*: How many current S&P 500 stocks have been in the index for more than 20 years? When stocks are added to the S&P 500, they usually experience a price bump as investors and index funds buy shares following the announcement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "113a9b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e6864fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_df = pd.read_html(\"http://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a5f8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub-Industry</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>Saint Paul, Minnesota</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>66740</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A. O. Smith</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Building Products</td>\n",
       "      <td>Milwaukee, Wisconsin</td>\n",
       "      <td>2017-07-26</td>\n",
       "      <td>91142</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>1800</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Biotechnology</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1551152</td>\n",
       "      <td>2013 (1888)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>XYL</td>\n",
       "      <td>Xylem Inc.</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Machinery &amp; Supplies &amp; Components</td>\n",
       "      <td>White Plains, New York</td>\n",
       "      <td>2011-11-01</td>\n",
       "      <td>1524472</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>YUM</td>\n",
       "      <td>Yum! Brands</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Louisville, Kentucky</td>\n",
       "      <td>1997-10-06</td>\n",
       "      <td>1041061</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>ZBRA</td>\n",
       "      <td>Zebra Technologies</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Electronic Equipment &amp; Instruments</td>\n",
       "      <td>Lincolnshire, Illinois</td>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>877212</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>ZBH</td>\n",
       "      <td>Zimmer Biomet</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>Warsaw, Indiana</td>\n",
       "      <td>2001-08-07</td>\n",
       "      <td>1136869</td>\n",
       "      <td>1927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>Parsippany, New Jersey</td>\n",
       "      <td>2013-06-21</td>\n",
       "      <td>1555280</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Symbol             Security             GICS Sector  \\\n",
       "0      MMM                   3M             Industrials   \n",
       "1      AOS          A. O. Smith             Industrials   \n",
       "2      ABT  Abbott Laboratories             Health Care   \n",
       "3     ABBV               AbbVie             Health Care   \n",
       "4      ACN            Accenture  Information Technology   \n",
       "..     ...                  ...                     ...   \n",
       "498    XYL           Xylem Inc.             Industrials   \n",
       "499    YUM          Yum! Brands  Consumer Discretionary   \n",
       "500   ZBRA   Zebra Technologies  Information Technology   \n",
       "501    ZBH        Zimmer Biomet             Health Care   \n",
       "502    ZTS               Zoetis             Health Care   \n",
       "\n",
       "                                GICS Sub-Industry    Headquarters Location  \\\n",
       "0                        Industrial Conglomerates    Saint Paul, Minnesota   \n",
       "1                               Building Products     Milwaukee, Wisconsin   \n",
       "2                           Health Care Equipment  North Chicago, Illinois   \n",
       "3                                   Biotechnology  North Chicago, Illinois   \n",
       "4                  IT Consulting & Other Services          Dublin, Ireland   \n",
       "..                                            ...                      ...   \n",
       "498  Industrial Machinery & Supplies & Components   White Plains, New York   \n",
       "499                                   Restaurants     Louisville, Kentucky   \n",
       "500            Electronic Equipment & Instruments   Lincolnshire, Illinois   \n",
       "501                         Health Care Equipment          Warsaw, Indiana   \n",
       "502                               Pharmaceuticals   Parsippany, New Jersey   \n",
       "\n",
       "     Date added      CIK      Founded  \n",
       "0    1957-03-04    66740         1902  \n",
       "1    2017-07-26    91142         1916  \n",
       "2    1957-03-04     1800         1888  \n",
       "3    2012-12-31  1551152  2013 (1888)  \n",
       "4    2011-07-06  1467373         1989  \n",
       "..          ...      ...          ...  \n",
       "498  2011-11-01  1524472         2011  \n",
       "499  1997-10-06  1041061         1997  \n",
       "500  2019-12-23   877212         1969  \n",
       "501  2001-08-07  1136869         1927  \n",
       "502  2013-06-21  1555280         1952  \n",
       "\n",
       "[503 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfbaacd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S&P 500 companies saved to sp500_companies.csv\n"
     ]
    }
   ],
   "source": [
    "# Optionally, save to a CSV file\n",
    "sp500_df.to_csv(\"data/sp500_companies.csv\", index=False)\n",
    "print(\"S&P 500 companies saved to sp500_companies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ddc247ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_added</th>\n",
       "      <th>addition_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1957</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2017</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2016</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2008</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2024</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2022</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2023</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2021</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2018</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year_added  addition_count\n",
       "0         1957              53\n",
       "48        2017              23\n",
       "47        2016              23\n",
       "50        2019              22\n",
       "39        2008              17\n",
       "55        2024              16\n",
       "53        2022              16\n",
       "54        2023              15\n",
       "52        2021              15\n",
       "49        2018              14"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the year with the most number of additions\n",
    "sp500_df['year_added'] = pd.to_datetime(sp500_df['Date added']).dt.year\n",
    "additions_df = sp500_df.groupby('year_added', as_index = False)['Symbol'].count().rename(columns={'Symbol': 'addition_count'}).sort_values(by='addition_count', ascending=False)\n",
    "additions_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ced9699e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The year(s) with the most additions (except 1957): 2017 with 23 additions.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The year(s) with the most additions (except 1957): {additions_df.iloc[1]['year_added']} with {additions_df.iloc[1]['addition_count']} additions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a04d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "*Additional*: How many current S&P 500 stocks have been in the index for more than 20 years? When stocks are added to the S&P 500, they usually experience a price bump as investors and index funds buy shares following the announcement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eb9690c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stocks that've been in the SP500 index for over 20 years: 219\n"
     ]
    }
   ],
   "source": [
    "sp500_df['Date added'] = pd.to_datetime(sp500_df['Date added'])\n",
    "sp500_df['duration_years'] = (pd.to_datetime('today').year - sp500_df['Date added'].dt.year)\n",
    "sp500_df['over_20_yrs'] = sp500_df['duration_years'] > 20\n",
    "print(f\"Number of stocks that've been in the SP500 index for over 20 years: {sp500_df['over_20_yrs'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5646b9cf",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 2. [Macro] Indexes YTD (as of 1 May 2025)\n",
    "\n",
    "**How many indexes (out of 10) have better year-to-date returns than the US (S&P 500) as of May 1, 2025?**\n",
    "\n",
    "Using Yahoo Finance World Indices data, compare the year-to-date (YTD) performance (1 January-1 May 2025) of major stock market indexes for the following countries:\n",
    "* United States - S&P 500 (^GSPC)\n",
    "* China - Shanghai Composite (000001.SS)\n",
    "* Hong Kong - HANG SENG INDEX (^HSI)\t\n",
    "* Australia - S&P/ASX 200 (^AXJO)\n",
    "* India - Nifty 50 (^NSEI)\n",
    "* Canada - S&P/TSX Composite (^GSPTSE)\n",
    "* Germany - DAX (^GDAXI)\n",
    "* United Kingdom - FTSE 100 (^FTSE)\n",
    "* Japan - Nikkei 225 (^N225)\n",
    "* Mexico - IPC Mexico (^MXX)\n",
    "* Brazil - Ibovespa (^BVSP)\n",
    "\n",
    "*Hint*: use start_date='2025-01-01' and end_date='2025-05-01' when downloading daily data in yfinance\n",
    "\n",
    "Context: \n",
    "> [Global Valuations: Who's Cheap, Who's Not?](https://simplywall.st/article/beyond-the-us-global-markets-after-yet-another-tariff-update) article suggests \"Other regions may be growing faster than the US and you need to diversify.\"\n",
    "\n",
    "Reference: Yahoo Finance World Indices - https://finance.yahoo.com/world-indices/\n",
    "\n",
    "*Additional*: How many of these indexes have better returns than the S&P 500 over 3, 5, and 10 year periods? Do you see the same trend?\n",
    "Note: For simplicity, ignore currency conversion effects.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a32750b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "00ad50e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in yahoo finance data\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e2c77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  11 of 11 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th colspan=\"5\" halign=\"left\">^GSPTSE</th>\n",
       "      <th colspan=\"5\" halign=\"left\">000001.SS</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"5\" halign=\"left\">^NSEI</th>\n",
       "      <th colspan=\"5\" halign=\"left\">^GSPC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>...</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>23637.650391</td>\n",
       "      <td>23822.800781</td>\n",
       "      <td>23562.800781</td>\n",
       "      <td>23742.900391</td>\n",
       "      <td>154900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02</th>\n",
       "      <td>24821.199219</td>\n",
       "      <td>25003.199219</td>\n",
       "      <td>24777.099609</td>\n",
       "      <td>24898.000000</td>\n",
       "      <td>215089400.0</td>\n",
       "      <td>3347.938965</td>\n",
       "      <td>3351.721924</td>\n",
       "      <td>3242.086914</td>\n",
       "      <td>3262.561035</td>\n",
       "      <td>561400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23783.000000</td>\n",
       "      <td>24226.699219</td>\n",
       "      <td>23751.550781</td>\n",
       "      <td>24188.650391</td>\n",
       "      <td>283200.0</td>\n",
       "      <td>5903.259766</td>\n",
       "      <td>5935.089844</td>\n",
       "      <td>5829.529785</td>\n",
       "      <td>5868.549805</td>\n",
       "      <td>3.621680e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-03</th>\n",
       "      <td>24940.000000</td>\n",
       "      <td>25086.000000</td>\n",
       "      <td>24940.000000</td>\n",
       "      <td>25073.500000</td>\n",
       "      <td>186569100.0</td>\n",
       "      <td>3267.076904</td>\n",
       "      <td>3273.565918</td>\n",
       "      <td>3205.775879</td>\n",
       "      <td>3211.429932</td>\n",
       "      <td>517600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24196.400391</td>\n",
       "      <td>24196.449219</td>\n",
       "      <td>23976.000000</td>\n",
       "      <td>24004.750000</td>\n",
       "      <td>312300.0</td>\n",
       "      <td>5891.069824</td>\n",
       "      <td>5949.339844</td>\n",
       "      <td>5888.660156</td>\n",
       "      <td>5942.470215</td>\n",
       "      <td>3.667340e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-06</th>\n",
       "      <td>25169.000000</td>\n",
       "      <td>25222.400391</td>\n",
       "      <td>24967.900391</td>\n",
       "      <td>24999.800781</td>\n",
       "      <td>239976800.0</td>\n",
       "      <td>3209.782959</td>\n",
       "      <td>3219.488037</td>\n",
       "      <td>3185.462891</td>\n",
       "      <td>3206.923096</td>\n",
       "      <td>431000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24045.800781</td>\n",
       "      <td>24089.949219</td>\n",
       "      <td>23551.900391</td>\n",
       "      <td>23616.050781</td>\n",
       "      <td>278100.0</td>\n",
       "      <td>5982.810059</td>\n",
       "      <td>6021.040039</td>\n",
       "      <td>5960.009766</td>\n",
       "      <td>5975.379883</td>\n",
       "      <td>4.940120e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-07</th>\n",
       "      <td>25059.900391</td>\n",
       "      <td>25197.000000</td>\n",
       "      <td>24863.900391</td>\n",
       "      <td>24929.900391</td>\n",
       "      <td>237759800.0</td>\n",
       "      <td>3203.306885</td>\n",
       "      <td>3230.853027</td>\n",
       "      <td>3190.460938</td>\n",
       "      <td>3229.644043</td>\n",
       "      <td>409700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23679.900391</td>\n",
       "      <td>23795.199219</td>\n",
       "      <td>23637.800781</td>\n",
       "      <td>23707.900391</td>\n",
       "      <td>262300.0</td>\n",
       "      <td>5993.259766</td>\n",
       "      <td>6000.680176</td>\n",
       "      <td>5890.680176</td>\n",
       "      <td>5909.029785</td>\n",
       "      <td>4.517330e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-24</th>\n",
       "      <td>24492.699219</td>\n",
       "      <td>24727.500000</td>\n",
       "      <td>24464.599609</td>\n",
       "      <td>24727.500000</td>\n",
       "      <td>224419200.0</td>\n",
       "      <td>3295.148926</td>\n",
       "      <td>3313.509033</td>\n",
       "      <td>3286.236084</td>\n",
       "      <td>3297.288086</td>\n",
       "      <td>392800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24277.900391</td>\n",
       "      <td>24347.849609</td>\n",
       "      <td>24216.150391</td>\n",
       "      <td>24246.699219</td>\n",
       "      <td>358800.0</td>\n",
       "      <td>5381.379883</td>\n",
       "      <td>5489.399902</td>\n",
       "      <td>5371.959961</td>\n",
       "      <td>5484.770020</td>\n",
       "      <td>4.697710e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-25</th>\n",
       "      <td>24669.699219</td>\n",
       "      <td>24719.000000</td>\n",
       "      <td>24602.199219</td>\n",
       "      <td>24710.500000</td>\n",
       "      <td>214234300.0</td>\n",
       "      <td>3300.392090</td>\n",
       "      <td>3305.261963</td>\n",
       "      <td>3288.754883</td>\n",
       "      <td>3295.060059</td>\n",
       "      <td>411000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24289.000000</td>\n",
       "      <td>24365.449219</td>\n",
       "      <td>23847.849609</td>\n",
       "      <td>24039.349609</td>\n",
       "      <td>387700.0</td>\n",
       "      <td>5489.729980</td>\n",
       "      <td>5528.109863</td>\n",
       "      <td>5455.859863</td>\n",
       "      <td>5525.209961</td>\n",
       "      <td>4.236580e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-28</th>\n",
       "      <td>24701.699219</td>\n",
       "      <td>24845.500000</td>\n",
       "      <td>24701.699219</td>\n",
       "      <td>24798.599609</td>\n",
       "      <td>224287200.0</td>\n",
       "      <td>3292.055908</td>\n",
       "      <td>3296.931885</td>\n",
       "      <td>3279.876953</td>\n",
       "      <td>3288.415039</td>\n",
       "      <td>410700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24070.250000</td>\n",
       "      <td>24355.099609</td>\n",
       "      <td>24054.050781</td>\n",
       "      <td>24328.500000</td>\n",
       "      <td>320500.0</td>\n",
       "      <td>5529.220215</td>\n",
       "      <td>5553.660156</td>\n",
       "      <td>5468.640137</td>\n",
       "      <td>5528.750000</td>\n",
       "      <td>4.257880e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-29</th>\n",
       "      <td>24766.400391</td>\n",
       "      <td>24910.000000</td>\n",
       "      <td>24743.699219</td>\n",
       "      <td>24874.500000</td>\n",
       "      <td>199905200.0</td>\n",
       "      <td>3281.445068</td>\n",
       "      <td>3294.981934</td>\n",
       "      <td>3277.626953</td>\n",
       "      <td>3286.655029</td>\n",
       "      <td>389000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24370.699219</td>\n",
       "      <td>24457.650391</td>\n",
       "      <td>24290.750000</td>\n",
       "      <td>24335.949219</td>\n",
       "      <td>357600.0</td>\n",
       "      <td>5508.870117</td>\n",
       "      <td>5571.950195</td>\n",
       "      <td>5505.700195</td>\n",
       "      <td>5560.830078</td>\n",
       "      <td>4.747150e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-30</th>\n",
       "      <td>24749.300781</td>\n",
       "      <td>24843.599609</td>\n",
       "      <td>24503.599609</td>\n",
       "      <td>24841.699219</td>\n",
       "      <td>271264200.0</td>\n",
       "      <td>3284.081055</td>\n",
       "      <td>3292.199951</td>\n",
       "      <td>3277.550049</td>\n",
       "      <td>3279.031006</td>\n",
       "      <td>435800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24342.050781</td>\n",
       "      <td>24396.150391</td>\n",
       "      <td>24198.750000</td>\n",
       "      <td>24334.199219</td>\n",
       "      <td>424500.0</td>\n",
       "      <td>5499.439941</td>\n",
       "      <td>5581.839844</td>\n",
       "      <td>5433.240234</td>\n",
       "      <td>5569.060059</td>\n",
       "      <td>5.449490e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker           ^GSPTSE                                            \\\n",
       "Price               Open          High           Low         Close   \n",
       "Date                                                                 \n",
       "2025-01-01           NaN           NaN           NaN           NaN   \n",
       "2025-01-02  24821.199219  25003.199219  24777.099609  24898.000000   \n",
       "2025-01-03  24940.000000  25086.000000  24940.000000  25073.500000   \n",
       "2025-01-06  25169.000000  25222.400391  24967.900391  24999.800781   \n",
       "2025-01-07  25059.900391  25197.000000  24863.900391  24929.900391   \n",
       "...                  ...           ...           ...           ...   \n",
       "2025-04-24  24492.699219  24727.500000  24464.599609  24727.500000   \n",
       "2025-04-25  24669.699219  24719.000000  24602.199219  24710.500000   \n",
       "2025-04-28  24701.699219  24845.500000  24701.699219  24798.599609   \n",
       "2025-04-29  24766.400391  24910.000000  24743.699219  24874.500000   \n",
       "2025-04-30  24749.300781  24843.599609  24503.599609  24841.699219   \n",
       "\n",
       "Ticker                     000001.SS                                         \\\n",
       "Price            Volume         Open         High          Low        Close   \n",
       "Date                                                                          \n",
       "2025-01-01          NaN          NaN          NaN          NaN          NaN   \n",
       "2025-01-02  215089400.0  3347.938965  3351.721924  3242.086914  3262.561035   \n",
       "2025-01-03  186569100.0  3267.076904  3273.565918  3205.775879  3211.429932   \n",
       "2025-01-06  239976800.0  3209.782959  3219.488037  3185.462891  3206.923096   \n",
       "2025-01-07  237759800.0  3203.306885  3230.853027  3190.460938  3229.644043   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "2025-04-24  224419200.0  3295.148926  3313.509033  3286.236084  3297.288086   \n",
       "2025-04-25  214234300.0  3300.392090  3305.261963  3288.754883  3295.060059   \n",
       "2025-04-28  224287200.0  3292.055908  3296.931885  3279.876953  3288.415039   \n",
       "2025-04-29  199905200.0  3281.445068  3294.981934  3277.626953  3286.655029   \n",
       "2025-04-30  271264200.0  3284.081055  3292.199951  3277.550049  3279.031006   \n",
       "\n",
       "Ticker                ...         ^NSEI                              \\\n",
       "Price         Volume  ...          Open          High           Low   \n",
       "Date                  ...                                             \n",
       "2025-01-01       NaN  ...  23637.650391  23822.800781  23562.800781   \n",
       "2025-01-02  561400.0  ...  23783.000000  24226.699219  23751.550781   \n",
       "2025-01-03  517600.0  ...  24196.400391  24196.449219  23976.000000   \n",
       "2025-01-06  431000.0  ...  24045.800781  24089.949219  23551.900391   \n",
       "2025-01-07  409700.0  ...  23679.900391  23795.199219  23637.800781   \n",
       "...              ...  ...           ...           ...           ...   \n",
       "2025-04-24  392800.0  ...  24277.900391  24347.849609  24216.150391   \n",
       "2025-04-25  411000.0  ...  24289.000000  24365.449219  23847.849609   \n",
       "2025-04-28  410700.0  ...  24070.250000  24355.099609  24054.050781   \n",
       "2025-04-29  389000.0  ...  24370.699219  24457.650391  24290.750000   \n",
       "2025-04-30  435800.0  ...  24342.050781  24396.150391  24198.750000   \n",
       "\n",
       "Ticker                                    ^GSPC                            \\\n",
       "Price              Close    Volume         Open         High          Low   \n",
       "Date                                                                        \n",
       "2025-01-01  23742.900391  154900.0          NaN          NaN          NaN   \n",
       "2025-01-02  24188.650391  283200.0  5903.259766  5935.089844  5829.529785   \n",
       "2025-01-03  24004.750000  312300.0  5891.069824  5949.339844  5888.660156   \n",
       "2025-01-06  23616.050781  278100.0  5982.810059  6021.040039  5960.009766   \n",
       "2025-01-07  23707.900391  262300.0  5993.259766  6000.680176  5890.680176   \n",
       "...                  ...       ...          ...          ...          ...   \n",
       "2025-04-24  24246.699219  358800.0  5381.379883  5489.399902  5371.959961   \n",
       "2025-04-25  24039.349609  387700.0  5489.729980  5528.109863  5455.859863   \n",
       "2025-04-28  24328.500000  320500.0  5529.220215  5553.660156  5468.640137   \n",
       "2025-04-29  24335.949219  357600.0  5508.870117  5571.950195  5505.700195   \n",
       "2025-04-30  24334.199219  424500.0  5499.439941  5581.839844  5433.240234   \n",
       "\n",
       "Ticker                                 \n",
       "Price             Close        Volume  \n",
       "Date                                   \n",
       "2025-01-01          NaN           NaN  \n",
       "2025-01-02  5868.549805  3.621680e+09  \n",
       "2025-01-03  5942.470215  3.667340e+09  \n",
       "2025-01-06  5975.379883  4.940120e+09  \n",
       "2025-01-07  5909.029785  4.517330e+09  \n",
       "...                 ...           ...  \n",
       "2025-04-24  5484.770020  4.697710e+09  \n",
       "2025-04-25  5525.209961  4.236580e+09  \n",
       "2025-04-28  5528.750000  4.257880e+09  \n",
       "2025-04-29  5560.830078  4.747150e+09  \n",
       "2025-04-30  5569.060059  5.449490e+09  \n",
       "\n",
       "[86 rows x 55 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define index tickers\n",
    "indices = ['^GSPC', '000001.SS', '^HSI', '^AXJO', '^NSEI', '^GSPTSE', '^GDAXI', '^FTSE', '^N225', '^MXX', '^BVSP']\n",
    "\n",
    "# Download historical data for the indices\n",
    "macro_df = yf.download(indices, start = '2025-01-01', end = '2025-05-01', group_by='ticker')\n",
    "\n",
    "macro_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b5fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize ytd dict\n",
    "ytd_returns = {}\n",
    "\n",
    "for ticker in indices:\n",
    "    try:\n",
    "        data = macro_df[ticker]['Close'].dropna()\n",
    "        start_price = data.iloc[0]\n",
    "        end_price = data.iloc[-1]\n",
    "        ytd_return = (end_price - start_price) / start_price * 100\n",
    "        ytd_returns[ticker] = ytd_return\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {e}\")\n",
    "\n",
    "# convert to df and sort\n",
    "ytd_df = pd.DataFrame.from_dict(ytd_returns, orient='index', columns=['YTD Return']).sort_values(by='YTD Return', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554fc973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YTD Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>^MXX</th>\n",
       "      <td>13.049444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>^HSI</th>\n",
       "      <td>12.720018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>^BVSP</th>\n",
       "      <td>12.438710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>^GDAXI</th>\n",
       "      <td>12.346378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>^FTSE</th>\n",
       "      <td>2.842590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>^NSEI</th>\n",
       "      <td>2.490424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000001.SS</th>\n",
       "      <td>0.504817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>^GSPTSE</th>\n",
       "      <td>-0.226126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>^AXJO</th>\n",
       "      <td>-0.914500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>^GSPC</th>\n",
       "      <td>-5.103301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>^N225</th>\n",
       "      <td>-8.297931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           YTD Return\n",
       "^MXX        13.049444\n",
       "^HSI        12.720018\n",
       "^BVSP       12.438710\n",
       "^GDAXI      12.346378\n",
       "^FTSE        2.842590\n",
       "^NSEI        2.490424\n",
       "000001.SS    0.504817\n",
       "^GSPTSE     -0.226126\n",
       "^AXJO       -0.914500\n",
       "^GSPC       -5.103301\n",
       "^N225       -8.297931"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b8796b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 indexes had better YTD return than the US (S&P 500).\n"
     ]
    }
   ],
   "source": [
    "sp500_ytd = ytd_returns['^GSPC']\n",
    "better_than_sp500 = sum([r > sp500_ytd for r in ytd_returns.values()])\n",
    "print(f\"{better_than_sp500} indexes had better YTD return than the US (S&P 500).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf02a35",
   "metadata": {},
   "source": [
    "Additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2f9b95ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  11 of 11 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  3Y         5Y         10Y\n",
      "^GSPC      34.864689  97.976487  165.814477\n",
      "000001.SS       None       None        None\n",
      "^HSI            None       None        None\n",
      "^AXJO      10.869744  55.275553   40.093565\n",
      "^NSEI           None       None        None\n",
      "^GSPTSE    19.830663  69.597067   61.642263\n",
      "^GDAXI          None       None        None\n",
      "^FTSE      12.372211  47.434535   21.626107\n",
      "^N225      35.922072  85.797702   86.632141\n",
      "^MXX            None       None        None\n",
      "^BVSP           None       None        None\n",
      "1 indexes had better 3Y return than S&P 500 (34.86%).\n",
      "0 indexes had better 5Y return than S&P 500 (97.98%).\n",
      "0 indexes had better 10Y return than S&P 500 (165.81%).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# List of index tickers\n",
    "indices = ['^GSPC', '000001.SS', '^HSI', '^AXJO', '^NSEI', '^GSPTSE', '^GDAXI', '^FTSE', '^N225', '^MXX', '^BVSP']\n",
    "\n",
    "# Download full historical data since 2015\n",
    "full_df = yf.download(indices, start='2015-01-01', end='2025-05-02', group_by='ticker', auto_adjust=True)\n",
    "\n",
    "# Helper function to get return over a given window\n",
    "def calculate_return(data, start_date, end_date):\n",
    "    try:\n",
    "        start_price = data[data.index >= pd.to_datetime(start_date)].iloc[0]\n",
    "        end_price = data[data.index >= pd.to_datetime(end_date)].iloc[0]\n",
    "        return (end_price - start_price) / start_price * 100\n",
    "    except:\n",
    "        return None  # If price data isn't available\n",
    "\n",
    "# Define time periods\n",
    "periods = {\n",
    "    '3Y': ('2022-05-01', '2025-05-01'),\n",
    "    '5Y': ('2020-05-01', '2025-05-01'),\n",
    "    '10Y': ('2015-05-01', '2025-05-01')\n",
    "}\n",
    "\n",
    "# Store returns\n",
    "returns = {ticker: {} for ticker in indices}\n",
    "\n",
    "for ticker in indices:\n",
    "    try:\n",
    "        close_prices = full_df[ticker]['Close'].dropna()\n",
    "        for label, (start, end) in periods.items():\n",
    "            returns[ticker][label] = calculate_return(close_prices, start, end)\n",
    "    except Exception as e:\n",
    "        print(f\"Error for {ticker}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "returns_df = pd.DataFrame(returns).T\n",
    "print(returns_df)\n",
    "\n",
    "# Compare to S&P 500 for each period\n",
    "for period in periods:\n",
    "    sp500 = returns_df.loc['^GSPC', period]\n",
    "    count = (returns_df[period] > sp500).sum()\n",
    "    print(f\"{count} indexes had better {period} return than S&P 500 ({sp500:.2f}%).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff917d1",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### Question 3. [Index] S&P 500 Market Corrections Analysis\n",
    "\n",
    "\n",
    "**Calculate the median duration (in days) of significant market corrections in the S&P 500 index.**\n",
    "\n",
    "For this task, define a correction as an event when a stock index goes down by **more than 5%** from the closest all-time high maximum.\n",
    "\n",
    "Steps:\n",
    "1. Download S&P 500 historical data (1950-present) using yfinance\n",
    "2. Identify all-time high points (where price exceeds all previous prices)\n",
    "3. For each pair of consecutive all-time highs, find the minimum price in between\n",
    "4. Calculate drawdown percentages: (high - low) / high × 100\n",
    "5. Filter for corrections with at least 5% drawdown\n",
    "6. Calculate the duration in days for each correction period\n",
    "7. Determine the 25th, 50th (median), and 75th percentiles for correction durations\n",
    "\n",
    "*Context:* \n",
    "> * Investors often wonder about the typical length of market corrections when deciding \"when to buy the dip\" ([Reddit discussion](https://www.reddit.com/r/investing/comments/1jrqnte/when_are_you_buying_the_dip/?rdt=64135)).\n",
    "\n",
    "> * [A Wealth of Common Sense - How Often Should You Expect a Stock Market Correction?](https://awealthofcommonsense.com/2022/01/how-often-should-you-expect-a-stock-market-correction/)\n",
    "\n",
    "*Hint (use this data to compare with your results)*: Here is the list of top 10 largest corrections by drawdown:\n",
    "* 2007-10-09 to 2009-03-09: 56.8% drawdown over 517 days\n",
    "* 2000-03-24 to 2002-10-09: 49.1% drawdown over 929 days\n",
    "* 1973-01-11 to 1974-10-03: 48.2% drawdown over 630 days\n",
    "* 1968-11-29 to 1970-05-26: 36.1% drawdown over 543 days\n",
    "* 2020-02-19 to 2020-03-23: 33.9% drawdown over 33 days\n",
    "* 1987-08-25 to 1987-12-04: 33.5% drawdown over 101 days\n",
    "* 1961-12-12 to 1962-06-26: 28.0% drawdown over 196 days\n",
    "* 1980-11-28 to 1982-08-12: 27.1% drawdown over 622 days\n",
    "* 2022-01-03 to 2022-10-12: 25.4% drawdown over 282 days\n",
    "* 1966-02-09 to 1966-10-07: 22.2% drawdown over 240 days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e8f00628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and prepare data\n",
    "sp500 = yf.download(\"^GSPC\", start=\"1950-01-01\", progress=False)\n",
    "sp500 = sp500[['Close']].dropna()\n",
    "\n",
    "# Calculate all-time highs\n",
    "sp500['AllTimeHigh'] = sp500['Close'].cummax()\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d890a7",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### Question 4.  [Stocks] Earnings Surprise Analysis for Amazon (AMZN)\n",
    "\n",
    "\n",
    "**Calculate the median 2-day percentage change in stock prices following positive earnings surprises days.**\n",
    "\n",
    "Steps:\n",
    "1. Load earnings data from CSV ([ha1_Amazon.csv](ha1_Amazon.csv)) containing earnings dates, EPS estimates, and actual EPS. Make sure you are using the correct delimiter to read the data, such as in this command ```python pandas.read_csv(\"ha1_Amazon.csv\", delimiter=';') ```\n",
    "2. Download complete historical price data using yfinance\n",
    "3. Calculate 2-day percentage changes for all historical dates: for each sequence of 3 consecutive trading days (Day 1, Day 2, Day 3), compute the *return* as Close_Day3 / Close_Day1 - 1. (Assume Day 2 may correspond to the earnings announcement.)\n",
    "4. Identify positive earnings surprises (where \"actual EPS > estimated EPS\"). Both fields should be present in the file. You should obtain 36 data points for use in the descriptive analysis (median) later. \n",
    "5. Calculate 2-day percentage changes following positive earnings surprises. Show your answer in % (closest number to the 2nd digit): *return* * 100.0\n",
    "6. (Optional) Compare the median 2-day percentage change for positive surprises vs. all historical dates. Do you see the difference?\n",
    "\n",
    "Context: Earnings announcements, especially when they exceed analyst expectations, can significantly impact stock prices in the short term.\n",
    "\n",
    "Reference: Yahoo Finance earnings calendar - https://finance.yahoo.com/calendar/earnings?symbol=AMZN\n",
    "\n",
    "*Additional*: Is there a correlation between the magnitude of the earnings surprise and the stock price reaction? Does the market react differently to earnings surprises during bull vs. bear markets?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a388e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad9bb16a",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 5.  [Exploratory, optional] Brainstorm potential idea for your capstone project\n",
    "\n",
    "**Free text answer**\n",
    "\n",
    "Describe the capstone project you would like to pursue, considering your aspirations, ML model predictions, and prior knowledge. Even if you are unsure at this stage, try to generate an idea you would like to explore-such as a specific asset class, country, industry vertical, or investment strategy. Be as specific as possible.\n",
    "\n",
    "*Example: I want to build a short-term prediction model for the US/India/Brazil stock markets, focusing on the largest stocks over a 30-day investment horizon. I plan to use RSI and MACD technical indicators and news coverage data to generate predictions.*\n",
    "\n",
    "---\n",
    "### Question 6. [Exploratory, optional] Investigate new metrics\n",
    "\n",
    "**Free text answer**\n",
    "\n",
    "Using the data sources we have covered (or any others you find relevant), download and explore a few additional metrics or time series that could be valuable for your project. Briefly explain why you think each metric is useful. This does not need to be a comprehensive list-focus on demonstrating your ability to generate data requests based on your project description, identify and locate the necessary data, and explain how you would retrieve it using Python.\n",
    "\n",
    "## Submitting the solutions\n",
    "\n",
    "Form for submitting: https://courses.datatalks.club/sma-zoomcamp-2025/homework/hw01\n",
    "\n",
    "---\n",
    "## Leaderboard\n",
    "\n",
    "Leaderboard link: https://courses.datatalks.club/sma-zoomcamp-2025/leaderboard\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9493ee5b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
